{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.cm as cm\n",
    "# plt.style.use('ggplot')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xdd67354978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize the RGB codes by dividing it to the max RGB value to scale the data to [0,1]\n",
    "x_train, x_test = x_train/255, x_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try an initial model\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 266us/step - loss: 0.2019 - acc: 0.9410\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.0802 - acc: 0.9758\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 0.0526 - acc: 0.9840\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.0377 - acc: 0.9884\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.0271 - acc: 0.9912\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0225 - acc: 0.9932\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.0163 - acc: 0.9948\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.0147 - acc: 0.9952\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.0123 - acc: 0.9961\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.0113 - acc: 0.9962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xdd6739d048>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 37us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08117858811497572, 0.9817]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.0102 - acc: 0.9968\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0xdd635255f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## callback can be used to stop model training when achieved certain accuracy\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc')>0.98):\n",
    "            print(\"\\nReached 98% accuracy so cancelling training!\")\n",
    "            self.model.stop_training = True\n",
    "model.fit(x_train, y_train, epochs=10, callbacks=[myCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 35us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08451633539451323, 0.981]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## confusion matrix of classifier\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred_label = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.97      0.99      0.98      1032\n",
      "           3       0.97      0.98      0.97      1010\n",
      "           4       0.99      0.97      0.98       982\n",
      "           5       0.99      0.97      0.98       892\n",
      "           6       0.99      0.98      0.98       958\n",
      "           7       0.99      0.96      0.98      1028\n",
      "           8       0.98      0.99      0.98       974\n",
      "           9       0.96      0.98      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\* Tune parameter: try add more neurons, add more layers, adjust dropout rate, .... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Flatten,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x_train,y_train,x_test,y_test,\n",
    "               n_neurons=[512,128,64],dropout=True,dropout_rate=0.5):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(28, 28)))\n",
    "    for i in range(len(n_neurons)):\n",
    "        model.add(Dense(n_neurons[i], activation='relu'))\n",
    "        if dropout == True:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "                               \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=10, callbacks=[myCallback()])\n",
    "                  \n",
    "    return model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mlp_result = pd.DataFrame(columns=[\"n_neurons\",\"dropout\",\"dropout_rate\",\"test_acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.2723 - acc: 0.9192\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.1384 - acc: 0.9585\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.1061 - acc: 0.9671\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.0915 - acc: 0.9709\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.0828 - acc: 0.9739\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 0.0724 - acc: 0.9764\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.0667 - acc: 0.9789\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 0.0625 - acc: 0.9799\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 17s 287us/step - loss: 0.0599 - acc: 0.9810\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 71us/step\n",
      "0.9823\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.2245 - acc: 0.9329\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.1019 - acc: 0.9693\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.0737 - acc: 0.9772\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.0586 - acc: 0.9811\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "0.9803\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.2023 - acc: 0.9399\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 19s 311us/step - loss: 0.0811 - acc: 0.9754\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 20s 327us/step - loss: 0.0532 - acc: 0.9829\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 73us/step\n",
      "0.9798\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 19s 323us/step - loss: 0.2006 - acc: 0.9408\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 19s 309us/step - loss: 0.0787 - acc: 0.9760\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.0510 - acc: 0.9843\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 78us/step\n",
      "0.976\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 20s 335us/step - loss: 0.3672 - acc: 0.8885\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 19s 318us/step - loss: 0.1918 - acc: 0.9436\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 20s 326us/step - loss: 0.1588 - acc: 0.9545\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 20s 331us/step - loss: 0.1376 - acc: 0.9599\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.1245 - acc: 0.9631\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 0.1180 - acc: 0.9659\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 19s 315us/step - loss: 0.1093 - acc: 0.9676\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 0.1023 - acc: 0.9701\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 19s 314us/step - loss: 0.1001 - acc: 0.9702\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 21s 353us/step - loss: 0.0934 - acc: 0.9719\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 19s 312us/step - loss: 0.0879 - acc: 0.9740\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 19s 323us/step - loss: 0.0814 - acc: 0.9755\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 20s 341us/step - loss: 0.0820 - acc: 0.9761\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 20s 339us/step - loss: 0.0794 - acc: 0.9769\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 20s 332us/step - loss: 0.0799 - acc: 0.9774\n",
      "10000/10000 [==============================] - 1s 91us/step\n",
      "0.9798\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 22s 359us/step - loss: 0.2480 - acc: 0.9256\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 20s 329us/step - loss: 0.1201 - acc: 0.9633\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 20s 336us/step - loss: 0.0906 - acc: 0.9709\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 19s 318us/step - loss: 0.0772 - acc: 0.9759\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 19s 319us/step - loss: 0.0637 - acc: 0.9799\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 19s 322us/step - loss: 0.0600 - acc: 0.9812\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 95us/step\n",
      "0.9788\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 21s 347us/step - loss: 0.1893 - acc: 0.9430\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 19s 317us/step - loss: 0.0804 - acc: 0.9749\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 20s 326us/step - loss: 0.0546 - acc: 0.9821\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 95us/step\n",
      "0.9779\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 20s 341us/step - loss: 0.1897 - acc: 0.9439\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 20s 328us/step - loss: 0.0788 - acc: 0.9748\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 18s 304us/step - loss: 0.0543 - acc: 0.98260s - loss: 0\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 100us/step\n",
      "0.9765\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 6s 100us/step - loss: 0.7366 - acc: 0.7684\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.4346 - acc: 0.8738\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3782 - acc: 0.8919\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.3478 - acc: 0.9000\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3295 - acc: 0.9055\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3123 - acc: 0.9095\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.3048 - acc: 0.9116\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2914 - acc: 0.9158\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2859 - acc: 0.9179\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2797 - acc: 0.9201\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.2736 - acc: 0.9220\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2708 - acc: 0.9226\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2634 - acc: 0.9230\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2598 - acc: 0.9243\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.2605 - acc: 0.9253\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "0.9629\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 6s 108us/step - loss: 0.4402 - acc: 0.8658\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2354 - acc: 0.9297\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1931 - acc: 0.9431\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1692 - acc: 0.9493\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1560 - acc: 0.9528\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 5s 83us/step - loss: 0.1458 - acc: 0.9559\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1362 - acc: 0.9587\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1328 - acc: 0.9604\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.1246 - acc: 0.9615\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.1269 - acc: 0.9604\n",
      "Epoch 11/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1187 - acc: 0.9635\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.1150 - acc: 0.9648\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1136 - acc: 0.9654\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 5s 81us/step - loss: 0.1068 - acc: 0.9672\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 5s 80us/step - loss: 0.1051 - acc: 0.9672\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "0.9758\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.2794 - acc: 0.9188\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.1285 - acc: 0.9612\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0929 - acc: 0.9715\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0744 - acc: 0.9768\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 4s 74us/step - loss: 0.0601 - acc: 0.9810\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 70us/step\n",
      "0.9746\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 6s 94us/step - loss: 0.2870 - acc: 0.9154\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1298 - acc: 0.9608\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0956 - acc: 0.9709\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 5s 75us/step - loss: 0.0761 - acc: 0.9761\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.0624 - acc: 0.9811\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 74us/step\n",
      "0.9686\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 23s 386us/step - loss: 0.5520 - acc: 0.8337\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 20s 337us/step - loss: 0.2678 - acc: 0.9301\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 20s 334us/step - loss: 0.2168 - acc: 0.9435\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 20s 333us/step - loss: 0.1950 - acc: 0.9507\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 20s 334us/step - loss: 0.1778 - acc: 0.9544\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 20s 333us/step - loss: 0.1601 - acc: 0.9581\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 20s 338us/step - loss: 0.1490 - acc: 0.9608\n",
      "Epoch 8/15\n",
      "60000/60000 [==============================] - 20s 335us/step - loss: 0.1392 - acc: 0.9642\n",
      "Epoch 9/15\n",
      "60000/60000 [==============================] - 21s 344us/step - loss: 0.1333 - acc: 0.9648\n",
      "Epoch 10/15\n",
      "60000/60000 [==============================] - 22s 367us/step - loss: 0.1272 - acc: 0.9669\n",
      "Epoch 11/15\n",
      "60000/60000 [==============================] - 21s 357us/step - loss: 0.1232 - acc: 0.9685\n",
      "Epoch 12/15\n",
      "60000/60000 [==============================] - 20s 340us/step - loss: 0.1185 - acc: 0.9686\n",
      "Epoch 13/15\n",
      "60000/60000 [==============================] - 20s 335us/step - loss: 0.1118 - acc: 0.9711\n",
      "Epoch 14/15\n",
      "60000/60000 [==============================] - 20s 338us/step - loss: 0.1128 - acc: 0.9712\n",
      "Epoch 15/15\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.1072 - acc: 0.9717\n",
      "10000/10000 [==============================] - 1s 129us/step\n",
      "0.9814\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 25s 420us/step - loss: 0.3165 - acc: 0.9051\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 23s 385us/step - loss: 0.1473 - acc: 0.9575\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 23s 376us/step - loss: 0.1165 - acc: 0.9677\n",
      "Epoch 4/15\n",
      "60000/60000 [==============================] - 23s 390us/step - loss: 0.0950 - acc: 0.9730\n",
      "Epoch 5/15\n",
      "60000/60000 [==============================] - 21s 350us/step - loss: 0.0857 - acc: 0.97560s - loss: 0.\n",
      "Epoch 6/15\n",
      "60000/60000 [==============================] - 21s 355us/step - loss: 0.0743 - acc: 0.9786\n",
      "Epoch 7/15\n",
      "60000/60000 [==============================] - 21s 351us/step - loss: 0.0692 - acc: 0.9802\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 126us/step\n",
      "0.9815\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 22s 362us/step - loss: 0.2001 - acc: 0.9387\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 21s 344us/step - loss: 0.0861 - acc: 0.9733\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 23s 380us/step - loss: 0.0602 - acc: 0.9814\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 146us/step\n",
      "0.9768\n",
      "Epoch 1/15\n",
      "60000/60000 [==============================] - 24s 398us/step - loss: 0.1938 - acc: 0.9415\n",
      "Epoch 2/15\n",
      "60000/60000 [==============================] - 21s 354us/step - loss: 0.0859 - acc: 0.9732\n",
      "Epoch 3/15\n",
      "60000/60000 [==============================] - 21s 344us/step - loss: 0.0599 - acc: 0.9812\n",
      "\n",
      "Reached 98% accuracy so cancelling training!\n",
      "10000/10000 [==============================] - 1s 141us/step\n",
      "0.9728\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for n_neurons,dropout, dropout_rate in itertools.product([[512],[512,128],[64,64],[512,128,64]],[True,False],[0.5,0.25]):\n",
    "    res = build_model(x_train,y_train,x_test,y_test,n_neurons=n_neurons,dropout=dropout,dropout_rate=dropout_rate)\n",
    "    print(res[1])\n",
    "    df_mlp_result.loc[count] = [str(n_neurons),dropout,dropout_rate,res[1]]\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>dropout</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>test_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[512]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[512, 128, 64]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[512, 128, 64]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[512]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[512]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[512, 128]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[512, 128]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[512, 128]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[512, 128, 64]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[512, 128]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[512]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[512, 128, 64]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>False</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[64, 64]</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.9629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         n_neurons  dropout  dropout_rate  test_acc\n",
       "0            [512]     True          0.50    0.9823\n",
       "13  [512, 128, 64]     True          0.25    0.9815\n",
       "12  [512, 128, 64]     True          0.50    0.9814\n",
       "1            [512]     True          0.25    0.9803\n",
       "2            [512]    False          0.50    0.9798\n",
       "4       [512, 128]     True          0.50    0.9798\n",
       "5       [512, 128]     True          0.25    0.9788\n",
       "6       [512, 128]    False          0.50    0.9779\n",
       "14  [512, 128, 64]    False          0.50    0.9768\n",
       "7       [512, 128]    False          0.25    0.9765\n",
       "3            [512]    False          0.25    0.9760\n",
       "9         [64, 64]     True          0.25    0.9758\n",
       "10        [64, 64]    False          0.50    0.9746\n",
       "15  [512, 128, 64]    False          0.25    0.9728\n",
       "11        [64, 64]    False          0.25    0.9686\n",
       "8         [64, 64]     True          0.50    0.9629"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mlp_result.sort_values('test_acc',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### increasing hidden layers doesn't improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
